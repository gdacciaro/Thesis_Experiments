{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Experiment 1\n"
   ],
   "metadata": {
    "id": "szQteeChtEVH"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Setup"
   ],
   "metadata": {
    "id": "81cipUPKtHNu"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install --upgrade --no-cache-dir gdown &> /dev/null\n",
    "!pip install --upgrade --no-cache-dir POT &> /dev/null\n",
    "!pip uninstall torch -y &> /dev/null\n",
    "!pip install torch==1.13.1 &> /dev/null"
   ],
   "metadata": {
    "id": "JZ9PmEjluO_O",
    "ExecuteTime": {
     "start_time": "2023-05-01T15:04:52.296755Z",
     "end_time": "2023-05-01T15:06:26.845688Z"
    }
   },
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "qbLzOInfnCag",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "8df03d5e-b054-4a53-e904-221d0ee6e347",
    "ExecuteTime": {
     "start_time": "2023-05-01T15:06:26.859504Z",
     "end_time": "2023-05-01T15:07:06.488271Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gennarodanieleacciaro/PycharmProjects/tesi_experiments/venv/lib/python3.9/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: 'dlopen(/Users/gennarodanieleacciaro/PycharmProjects/tesi_experiments/venv/lib/python3.9/site-packages/torchvision/image.so, 0x0006): Symbol not found: __ZN3c106detail19maybe_wrap_dim_slowIxEET_S2_S2_b\n",
      "  Referenced from: <0F72FEF0-4DF1-3E8A-90BA-513122A1950F> /Users/gennarodanieleacciaro/PycharmProjects/tesi_experiments/venv/lib/python3.9/site-packages/torchvision/image.so\n",
      "  Expected in:     <57D24B07-8B24-3888-A2B5-2B4C95434BA4> /Users/gennarodanieleacciaro/PycharmProjects/tesi_experiments/venv/lib/python3.9/site-packages/torch/lib/libc10.dylib'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import ot\n",
    "import time\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torchvision "
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "print(\"Pytorch version is \", torch.__version__)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f--1uFjV1ap-",
    "outputId": "05851b79-cb13-49e7-e62d-7edb37fb999f"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Pytorch version is  1.13.1+cu117\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Constants\n",
    "NUMPY_SEED = 100\n",
    "np.random.seed(NUMPY_SEED)\n",
    "\n",
    "GPU_USED = -1 # -1 = CPU"
   ],
   "metadata": {
    "id": "k6YV1DYcve4f",
    "ExecuteTime": {
     "start_time": "2023-05-01T15:13:55.765694Z",
     "end_time": "2023-05-01T15:13:55.776643Z"
    }
   },
   "execution_count": 22,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Args\n",
    "batch_size_train = 64\n",
    "batch_size_test = 1000\n",
    "activation_histograms = True\n",
    "act_num_samples = 200\n",
    "activation_mode = \"raw\"\n",
    "activation_seed = 21\n",
    "disable_bias = True\n",
    "personal_class_idx = 9\n",
    "prelu_acts = True\n",
    "unbalanced = False\n",
    "importance = None\n",
    "exact = False #OT Exact mode\n",
    "ensemble_step = 0.5\n",
    "eval_aligned = False\n",
    "softmax_temperature = 1\n",
    "past_correction = True\n",
    "skip_last_layer = False\n",
    "reg = 0.01\n",
    "correction = True\n",
    "proper_marginals = False\n",
    "width_ratio = 1\n",
    "\n",
    "ground_metric = 'euclidean'\n",
    "ground_metric_normalize = 'none'\n",
    "ground_metric_eff = False\n",
    "not_squared = True\n",
    "geom_ensemble_type = \"acts\"\n",
    "normalize_wts = False\n",
    "clip_gm = False\n",
    "\n",
    "ground_metric_params = {\n",
    "    \"ground_metric\": ground_metric,\n",
    "    \"reg\": reg,\n",
    "    \"ground_metric_normalize\": ground_metric_normalize,\n",
    "    \"ground_metric_eff\": ground_metric_eff,\n",
    "    \"not_squared\": not_squared,\n",
    "    \"geom_ensemble_type\": geom_ensemble_type,\n",
    "    \"normalize_wts\":normalize_wts,\n",
    "    \"clip_gm\":clip_gm\n",
    "}"
   ],
   "metadata": {
    "id": "bLbhyifO2qa3",
    "ExecuteTime": {
     "start_time": "2023-05-01T15:12:30.350293Z",
     "end_time": "2023-05-01T15:12:30.371622Z"
    }
   },
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Download and unzip MNIST models\n",
    "mnist_models_fileid = \"1SJTxBpi2Ln3XukcJLJNFIv8S2ix_M2sp\"\n",
    "!gdown $mnist_models_fileid \n",
    "!rm -rf mnist_models\n",
    "!unzip mnist_models.zip"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MMf3oUktt4DQ",
    "outputId": "1cb367af-6c65-4746-e413-297d5bbb1f20",
    "ExecuteTime": {
     "start_time": "2023-05-01T15:12:30.826275Z",
     "end_time": "2023-05-01T15:12:37.922391Z"
    }
   },
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading...\r\n",
      "From: https://drive.google.com/uc?id=1SJTxBpi2Ln3XukcJLJNFIv8S2ix_M2sp\r\n",
      "To: /Users/gennarodanieleacciaro/PycharmProjects/tesi_experiments/mnist_models.zip\r\n",
      "100%|██████████████████████████████████████| 3.07M/3.07M [00:01<00:00, 2.79MB/s]\r\n",
      "Archive:  mnist_models.zip\r\n",
      "   creating: mnist_models/\r\n",
      "   creating: mnist_models/mnsit/\r\n",
      "   creating: mnist_models/model_0/\r\n",
      "   creating: mnist_models/model_1/\r\n",
      "  inflating: mnist_models/model_0/final.checkpoint  \r\n",
      "  inflating: mnist_models/model_1/final.checkpoint  \r\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Functions from original code"
   ],
   "metadata": {
    "id": "u7VrEocvvmtR"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "class MlpNet(nn.Module):\n",
    "    def __init__(self, width_ratio=-1):\n",
    "        super(MlpNet, self).__init__()\n",
    "        input_dim = 784 # [mnist] 28 x 28 x 1\n",
    "        if width_ratio != -1:\n",
    "            self.width_ratio = width_ratio\n",
    "        else:\n",
    "            self.width_ratio = 1\n",
    "\n",
    "        self.fc1 = nn.Linear(input_dim, int(400/self.width_ratio), bias=not True)\n",
    "        self.fc2 = nn.Linear(int(400/self.width_ratio), int(200/self.width_ratio), bias=not True)\n",
    "        self.fc3 = nn.Linear(int(200/self.width_ratio), int(100/self.width_ratio), bias=not True)\n",
    "        self.fc4 = nn.Linear(int(100/self.width_ratio), 10, bias=not True)\n",
    "        self.enable_dropout = False\n",
    "\n",
    "    def forward(self, x, disable_logits=False):\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        if self.enable_dropout:\n",
    "            x = F.dropout(x, training=self.training)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        if self.enable_dropout:\n",
    "            x = F.dropout(x, training=self.training)\n",
    "        x = F.relu(self.fc3(x))\n",
    "        if self.enable_dropout:\n",
    "            x = F.dropout(x, training=self.training)\n",
    "        x = self.fc4(x)\n",
    "\n",
    "        if disable_logits:\n",
    "            return x\n",
    "        else:\n",
    "            return F.log_softmax(x)"
   ],
   "metadata": {
    "id": "TETefZEOv3kK",
    "ExecuteTime": {
     "start_time": "2023-05-01T15:12:43.598967Z",
     "end_time": "2023-05-01T15:12:43.647920Z"
    }
   },
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def get_pretrained_model(path, data_separated=False):\n",
    "    model = MlpNet()\n",
    "\n",
    "    \n",
    "    if GPU_USED != -1:\n",
    "        state = torch.load(\n",
    "            path, map_location=(\n",
    "                lambda s, _: torch.serialization.default_restore_location(s, 'cuda:' + str(GPU_USED))\n",
    "            ),)\n",
    "    else:\n",
    "        state = torch.load(\n",
    "            path, map_location=(\n",
    "                lambda s, _: torch.serialization.default_restore_location(s, 'cpu')\n",
    "            ),)\n",
    "\n",
    "    model_state_dict = state['model_state_dict']\n",
    "\n",
    "    if 'test_accuracy' not in state:\n",
    "        state['test_accuracy'] = -1\n",
    "\n",
    "    if 'epoch' not in state:\n",
    "        state['epoch'] = -1\n",
    "\n",
    "    if not data_separated:\n",
    "        print(\"Loading model at path {} which had accuracy {} and at epoch {}\".format(path, state['test_accuracy'],\n",
    "                                                                                  state['epoch']))\n",
    "    else:\n",
    "        print(\"Loading model at path {} which had local accuracy {} and overall accuracy {} for choice {} at epoch {}\".format(path,\n",
    "            state['local_test_accuracy'], state['test_accuracy'], state['choice'], state['epoch']))\n",
    "\n",
    "    model.load_state_dict(model_state_dict)\n",
    "\n",
    "    if GPU_USED != -1:\n",
    "        model = model.cuda(GPU_USED)\n",
    "\n",
    "    if not data_separated:\n",
    "        return model, state['test_accuracy']\n",
    "    else:\n",
    "        return model, state['test_accuracy'], state['local_test_accuracy']\n"
   ],
   "metadata": {
    "id": "W3vce6quvqnx",
    "ExecuteTime": {
     "start_time": "2023-05-01T15:12:48.816783Z",
     "end_time": "2023-05-01T15:12:48.867782Z"
    }
   },
   "execution_count": 7,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def get_dataloader(unit_batch = False, no_randomness=False):\n",
    "    if unit_batch:\n",
    "        bsz = (1, 1)\n",
    "    else:\n",
    "        bsz = (batch_size_train, batch_size_test)\n",
    "\n",
    "    if no_randomness:\n",
    "        enable_shuffle = False\n",
    "    else:\n",
    "        enable_shuffle = True\n",
    "        \n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "          torchvision.datasets.MNIST('./files/', train=True, download=True,\n",
    "                                     transform=torchvision.transforms.Compose([\n",
    "                                       torchvision.transforms.ToTensor(),\n",
    "                                       torchvision.transforms.Normalize(\n",
    "                                           # only 1 channel\n",
    "                                           (0.1307,), (0.3081,))\n",
    "                                     ])),\n",
    "          batch_size=bsz[0], shuffle=enable_shuffle\n",
    "        )\n",
    "\n",
    "\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "          torchvision.datasets.MNIST('./files/', train=False, download=True,\n",
    "                 transform=torchvision.transforms.Compose([\n",
    "                   torchvision.transforms.ToTensor(),\n",
    "                   torchvision.transforms.Normalize(\n",
    "                       (0.1307,), (0.3081,))\n",
    "                 ])),\n",
    "          batch_size=bsz[1], shuffle=enable_shuffle\n",
    "        )\n",
    "\n",
    "    return train_loader, test_loader\n"
   ],
   "metadata": {
    "id": "ocSFvHx-2NKN",
    "ExecuteTime": {
     "start_time": "2023-05-01T15:12:49.039405Z",
     "end_time": "2023-05-01T15:12:49.105826Z"
    }
   },
   "execution_count": 8,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def compute_activations_across_models_v1(args, models, train_loader, num_samples, mode='mean',\n",
    "                                         dump_activations=False, dump_path=None):\n",
    "    torch.manual_seed(activation_seed)\n",
    "\n",
    "    # hook that computes the mean activations across data samples\n",
    "    def get_activation(activation, name):\n",
    "        def hook(model, input, output):\n",
    "            if name not in activation:\n",
    "                activation[name] = []\n",
    "\n",
    "            activation[name].append(output.detach())\n",
    "\n",
    "        return hook\n",
    "\n",
    "    # Prepare all the models\n",
    "    activations = {}\n",
    "    forward_hooks = []\n",
    "\n",
    "    assert disable_bias\n",
    "    # handle below for bias later on!\n",
    "    # print(\"list of model named params \", list(models[0].named_parameters()))\n",
    "    param_names = [tupl[0].replace('.weight', '') for tupl in models[0].named_parameters()]\n",
    "    for idx, model in enumerate(models):\n",
    "\n",
    "        # Initialize the activation dictionary for each model\n",
    "        activations[idx] = {}\n",
    "        layer_hooks = []\n",
    "        # Set forward hooks for all layers inside a model\n",
    "        for name, layer in model.named_modules():\n",
    "            if name == '':\n",
    "                print(\"excluded\")\n",
    "                continue\n",
    "            layer_hooks.append(layer.register_forward_hook(get_activation(activations[idx], name)))\n",
    "            print(\"set forward hook for layer named: \", name)\n",
    "\n",
    "        forward_hooks.append(layer_hooks)\n",
    "        # Set the model in train mode\n",
    "        model.train()\n",
    "\n",
    "    # Run the same data samples ('num_samples' many) across all the models\n",
    "    num_samples_processed = 0\n",
    "    num_personal_idx = 0\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        if num_samples_processed == num_samples:\n",
    "            break\n",
    "\n",
    "        if GPU_USED != -1:\n",
    "            data = data.cuda(GPU_USED)\n",
    "\n",
    "        if int(target.item()) == personal_class_idx:\n",
    "            num_personal_idx += 1\n",
    "\n",
    "        for idx, model in enumerate(models):\n",
    "            model(data)\n",
    "\n",
    "        num_samples_processed += 1\n",
    "\n",
    "    print(\"num_personal_idx \", num_personal_idx)\n",
    "\n",
    "    relu = torch.nn.ReLU()\n",
    "    maxpool = torch.nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "    avgpool = torch.nn.AvgPool2d(kernel_size=1, stride=1)\n",
    "\n",
    "    # Combine the activations generated across the number of samples to form importance scores\n",
    "    # The importance calculated is based on the 'mode' flag: which is either of 'mean', 'std', 'meanstd'\n",
    "\n",
    "    model_cfg = None\n",
    "    for idx in range(len(models)):\n",
    "        cfg_idx = 0\n",
    "        for lnum, layer in enumerate(activations[idx]):\n",
    "            print('***********')\n",
    "            activations[idx][layer] = torch.stack(activations[idx][layer])\n",
    "            print(\"min of act: {}, max: {}, mean: {}\".format(torch.min(activations[idx][layer]), torch.max(activations[idx][layer]), torch.mean(activations[idx][layer])))\n",
    "            if not prelu_acts and not lnum == (len(activations[idx])-1):\n",
    "                # print(\"activation was \", activations[idx][layer])\n",
    "                print(\"applying relu ---------------\")\n",
    "                activations[idx][layer] = relu(activations[idx][layer])\n",
    "                print(\"after RELU: min of act: {}, max: {}, mean: {}\".format(torch.min(activations[idx][layer]),\n",
    "                                                                 torch.max(activations[idx][layer]),\n",
    "                                                                 torch.mean(activations[idx][layer])))\n",
    "            if mode == 'mean':\n",
    "                activations[idx][layer] = activations[idx][layer].mean(dim=0)\n",
    "            elif mode == 'std':\n",
    "                activations[idx][layer] = activations[idx][layer].std(dim=0)\n",
    "            elif mode == 'meanstd':\n",
    "                activations[idx][layer] = activations[idx][layer].mean(dim=0) * activations[idx][layer].std(dim=0)\n",
    "\n",
    "    # Remove the hooks (as this was intefering with prediction ensembling)\n",
    "    for idx in range(len(forward_hooks)):\n",
    "        for hook in forward_hooks[idx]:\n",
    "            hook.remove()\n",
    "\n",
    "    return activations"
   ],
   "metadata": {
    "id": "FSXbSR9jAFhX",
    "ExecuteTime": {
     "start_time": "2023-05-01T15:12:49.619355Z",
     "end_time": "2023-05-01T15:12:49.630159Z"
    }
   },
   "execution_count": 9,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def get_model_activations(args, models, config=None, layer_name=None, selective=False, personal_dataset = None):\n",
    "    train_loader, test_loader = get_dataloader(unit_batch=True)\n",
    "    activations = compute_activations_across_models_v1(args, models,\n",
    "                                                          train_loader,\n",
    "                                                          act_num_samples,\n",
    "                                                          mode=activation_mode)\n",
    "    return activations\n",
    "                "
   ],
   "metadata": {
    "id": "M3pdTa9d4QAa",
    "ExecuteTime": {
     "start_time": "2023-05-01T15:12:50.119722Z",
     "end_time": "2023-05-01T15:12:50.168311Z"
    }
   },
   "execution_count": 10,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "\n",
    "class GroundMetric:\n",
    "    \"\"\"\n",
    "        Ground Metric object for Wasserstein computations:\n",
    "\n",
    "    \"\"\"\n",
    "    def isnan(self,x):\n",
    "      return x != x\n",
    "\n",
    "    def __init__(self, params, not_squared = False):\n",
    "        self.params = params\n",
    "        self.ground_metric_type = params[\"ground_metric\"]\n",
    "        self.ground_metric_normalize = params[\"ground_metric_normalize\"]\n",
    "        self.reg = params[\"reg\"]\n",
    "        self.squared = False\n",
    "        self.mem_eff = params[\"ground_metric_eff\"]\n",
    "\n",
    "    def _clip(self, ground_metric_matrix):\n",
    "        if self.params[\"debug\"]:\n",
    "            print(\"before clipping\", ground_metric_matrix.data)\n",
    "\n",
    "        percent_clipped = (float((ground_metric_matrix >= self.reg * self.params.clip_max).long().sum().data) \\\n",
    "                           / ground_metric_matrix.numel()) * 100\n",
    "        print(\"percent_clipped is (assumes clip_min = 0) \", percent_clipped)\n",
    "        #setattr(self.params, 'percent_clipped', percent_clipped)\n",
    "        # will keep the M' = M/reg in range clip_min and clip_max\n",
    "        ground_metric_matrix.clamp_(min=self.reg * self.params.clip_min,\n",
    "                                             max=self.reg * self.params.clip_max)\n",
    "        if self.params[\"debug\"]:\n",
    "            print(\"after clipping\", ground_metric_matrix.data)\n",
    "        return ground_metric_matrix\n",
    "\n",
    "    def _normalize(self, ground_metric_matrix):\n",
    "\n",
    "        if self.ground_metric_normalize == \"log\":\n",
    "            ground_metric_matrix = torch.log1p(ground_metric_matrix)\n",
    "        elif self.ground_metric_normalize == \"max\":\n",
    "            print(\"Normalizing by max of ground metric and which is \", ground_metric_matrix.max())\n",
    "            ground_metric_matrix = ground_metric_matrix / ground_metric_matrix.max()\n",
    "        elif self.ground_metric_normalize == \"median\":\n",
    "            print(\"Normalizing by median of ground metric and which is \", ground_metric_matrix.median())\n",
    "            ground_metric_matrix = ground_metric_matrix / ground_metric_matrix.median()\n",
    "        elif self.ground_metric_normalize == \"mean\":\n",
    "            print(\"Normalizing by mean of ground metric and which is \", ground_metric_matrix.mean())\n",
    "            ground_metric_matrix = ground_metric_matrix / ground_metric_matrix.mean()\n",
    "        elif self.ground_metric_normalize == \"none\":\n",
    "            return ground_metric_matrix\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "        return ground_metric_matrix\n",
    "\n",
    "    def _sanity_check(self, ground_metric_matrix):\n",
    "        assert not (ground_metric_matrix < 0).any()\n",
    "        assert not (self.isnan(ground_metric_matrix).any())\n",
    "\n",
    "    def _cost_matrix_xy(self, x, y, p=2, squared = True):\n",
    "        # TODO: Use this to guarantee reproducibility of previous results and then move onto better way\n",
    "        \"Returns the matrix of $|x_i-y_j|^p$.\"\n",
    "        x_col = x.unsqueeze(1)\n",
    "        y_lin = y.unsqueeze(0)\n",
    "        c = torch.sum((torch.abs(x_col - y_lin)) ** p, 2)\n",
    "        if not squared:\n",
    "            print(\"dont leave off the squaring of the ground metric\")\n",
    "            c = c ** (1/2)\n",
    "        return c\n",
    "\n",
    "\n",
    "    def _pairwise_distances(self, x, y=None, squared=True):\n",
    "        '''\n",
    "        Source: https://discuss.pytorch.org/t/efficient-distance-matrix-computation/9065/2\n",
    "        Input: x is a Nxd matrix\n",
    "               y is an optional Mxd matirx\n",
    "        Output: dist is a NxM matrix where dist[i,j] is the square norm between x[i,:] and y[j,:]\n",
    "                if y is not given then use 'y=x'.\n",
    "        i.e. dist[i,j] = ||x[i,:]-y[j,:]||^2\n",
    "        '''\n",
    "        x_norm = (x ** 2).sum(1).view(-1, 1)\n",
    "        if y is not None:\n",
    "            y_t = torch.transpose(y, 0, 1)\n",
    "            y_norm = (y ** 2).sum(1).view(1, -1)\n",
    "        else:\n",
    "            y_t = torch.transpose(x, 0, 1)\n",
    "            y_norm = x_norm.view(1, -1)\n",
    "\n",
    "        dist = x_norm + y_norm - 2.0 * torch.mm(x, y_t)\n",
    "        # Ensure diagonal is zero if x=y\n",
    "        dist = torch.clamp(dist, min=0.0)\n",
    "\n",
    "        if self.params.activation_histograms and self.params.dist_normalize:\n",
    "            dist = dist/self.params.act_num_samples\n",
    "            print(\"Divide squared distances by the num samples\")\n",
    "\n",
    "        if not squared:\n",
    "            print(\"dont leave off the squaring of the ground metric\")\n",
    "            dist = dist ** (1/2)\n",
    "\n",
    "        return dist\n",
    "\n",
    "    def _get_euclidean(self, coordinates, other_coordinates=None):\n",
    "        # TODO: Replace by torch.pdist (which is said to be much more memory efficient)\n",
    "\n",
    "        if other_coordinates is None:\n",
    "            matrix = torch.norm(\n",
    "                coordinates.view(coordinates.shape[0], 1, coordinates.shape[1]) \\\n",
    "                - coordinates, p=2, dim=2\n",
    "            )\n",
    "        else:\n",
    "            if self.mem_eff:\n",
    "                matrix = self._pairwise_distances(coordinates, other_coordinates, squared=self.squared)\n",
    "            else:\n",
    "                matrix = self._cost_matrix_xy(coordinates, other_coordinates, squared = self.squared)\n",
    "\n",
    "        return matrix\n",
    "\n",
    "    def _normed_vecs(self, vecs, eps=1e-9):\n",
    "        norms = torch.norm(vecs, dim=-1, keepdim=True)\n",
    "        print(\"stats of vecs are: mean {}, min {}, max {}, std {}\".format(\n",
    "            norms.mean(), norms.min(), norms.max(), norms.std()\n",
    "        ))\n",
    "        return vecs / (norms + eps)\n",
    "\n",
    "    def _get_cosine(self, coordinates, other_coordinates=None):\n",
    "        if other_coordinates is None:\n",
    "            matrix = coordinates / torch.norm(coordinates, dim=1, keepdim=True)\n",
    "            matrix = 1 - matrix @ matrix.t()\n",
    "        else:\n",
    "            matrix = 1 - torch.div(\n",
    "                coordinates @ other_coordinates.t(),\n",
    "                torch.norm(coordinates, dim=1).view(-1, 1) @ torch.norm(other_coordinates, dim=1).view(1, -1)\n",
    "            )\n",
    "        return matrix.clamp_(min=0)\n",
    "\n",
    "    def _get_angular(self, coordinates, other_coordinates=None):\n",
    "        pass\n",
    "\n",
    "    def get_metric(self, coordinates, other_coordinates=None):\n",
    "        get_metric_map = {\n",
    "            'euclidean': self._get_euclidean,\n",
    "            'cosine': self._get_cosine,\n",
    "            'angular': self._get_angular,\n",
    "        }\n",
    "        return get_metric_map[self.ground_metric_type](coordinates, other_coordinates)\n",
    "\n",
    "    def process(self, coordinates, other_coordinates=None):\n",
    "        print('Processing the coordinates to form ground_metric')\n",
    "        if self.params[\"geom_ensemble_type\"] == 'wts' and self.params[\"normalize_wts\"]:\n",
    "            print(\"In weight mode: normalizing weights to unit norm\")\n",
    "            coordinates = self._normed_vecs(coordinates)\n",
    "            if other_coordinates is not None:\n",
    "                other_coordinates = self._normed_vecs(other_coordinates)\n",
    "\n",
    "        ground_metric_matrix = self.get_metric(coordinates, other_coordinates)\n",
    "\n",
    "        self._sanity_check(ground_metric_matrix)\n",
    "\n",
    "        ground_metric_matrix = self._normalize(ground_metric_matrix)\n",
    "\n",
    "        self._sanity_check(ground_metric_matrix)\n",
    "\n",
    "        if self.params[\"clip_gm\"]:\n",
    "            ground_metric_matrix = self._clip(ground_metric_matrix)\n",
    "\n",
    "        self._sanity_check(ground_metric_matrix)\n",
    "\n",
    "        return ground_metric_matrix"
   ],
   "metadata": {
    "id": "8NELekZpFkJ0",
    "ExecuteTime": {
     "start_time": "2023-05-01T15:12:50.531742Z",
     "end_time": "2023-05-01T15:12:50.562424Z"
    }
   },
   "execution_count": 11,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def get_histogram(idx, cardinality, layer_name, activations=None, return_numpy = True, float64=False):\n",
    "    if activations is None:\n",
    "        # returns a uniform measure\n",
    "        if not unbalanced:\n",
    "            print(\"returns a uniform measure of cardinality: \", cardinality)\n",
    "            return np.ones(cardinality)/cardinality\n",
    "        else:\n",
    "            return np.ones(cardinality)\n",
    "    else:\n",
    "        # return softmax over the activations raised to a temperature\n",
    "        # layer_name is like 'fc1.weight', while activations only contains 'fc1'\n",
    "        print(activations[idx].keys())\n",
    "        unnormalized_weights = activations[idx][layer_name.split('.')[0]]\n",
    "        print(\"For layer {},  shape of unnormalized weights is \".format(layer_name), unnormalized_weights.shape)\n",
    "        unnormalized_weights = unnormalized_weights.squeeze()\n",
    "        assert unnormalized_weights.shape[0] == cardinality\n",
    "\n",
    "        if return_numpy:\n",
    "            if float64:\n",
    "                return torch.softmax(unnormalized_weights / softmax_temperature, dim=0).data.cpu().numpy().astype(\n",
    "                    np.float64)\n",
    "            else:\n",
    "                return torch.softmax(unnormalized_weights / softmax_temperature, dim=0).data.cpu().numpy()\n",
    "        else:\n",
    "            return torch.softmax(unnormalized_weights / softmax_temperature, dim=0)"
   ],
   "metadata": {
    "id": "SaUyDUqMGNcm",
    "ExecuteTime": {
     "start_time": "2023-05-01T15:12:51.640220Z",
     "end_time": "2023-05-01T15:12:51.687357Z"
    }
   },
   "execution_count": 12,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def get_wassersteinized_layers_modularized(args, networks, activations=None, eps=1e-7, test_loader=None):\n",
    "    '''\n",
    "    Two neural networks that have to be averaged in geometric manner (i.e. layerwise).\n",
    "    The 1st network is aligned with respect to the other via wasserstein distance.\n",
    "    Also this assumes that all the layers are either fully connected or convolutional *(with no bias)*\n",
    "\n",
    "    :param networks: list of networks\n",
    "    :param activations: If not None, use it to build the activation histograms.\n",
    "    Otherwise assumes uniform distribution over neurons in a layer.\n",
    "    :return: list of layer weights 'wassersteinized'\n",
    "    '''\n",
    "\n",
    "    avg_aligned_layers = []\n",
    "    T_var = None\n",
    "    previous_layer_shape = None\n",
    "    ground_metric_object = GroundMetric(ground_metric_params)\n",
    "\n",
    "    if eval_aligned:\n",
    "        model0_aligned_layers = []\n",
    "\n",
    "    if GPU_USED==-1:\n",
    "        device = torch.device('cpu')\n",
    "    else:\n",
    "        device = torch.device('cuda:{}'.format(GPU_USED))\n",
    "\n",
    "\n",
    "    num_layers = len(list(zip(networks[0].parameters(), networks[1].parameters())))\n",
    "    for idx, ((layer0_name, fc_layer0_weight), (layer1_name, fc_layer1_weight)) in \\\n",
    "            enumerate(zip(networks[0].named_parameters(), networks[1].named_parameters())):\n",
    "\n",
    "        assert fc_layer0_weight.shape == fc_layer1_weight.shape\n",
    "        previous_layer_shape = fc_layer1_weight.shape\n",
    "\n",
    "        mu_cardinality = fc_layer0_weight.shape[0]\n",
    "        nu_cardinality = fc_layer1_weight.shape[0]\n",
    "\n",
    "        layer_shape = fc_layer0_weight.shape\n",
    "        if len(layer_shape) > 2:\n",
    "            is_conv = True\n",
    "            # For convolutional layers, it is (#out_channels, #in_channels, height, width)\n",
    "            fc_layer0_weight_data = fc_layer0_weight.data.view(fc_layer0_weight.shape[0], fc_layer0_weight.shape[1], -1)\n",
    "            fc_layer1_weight_data = fc_layer1_weight.data.view(fc_layer1_weight.shape[0], fc_layer1_weight.shape[1], -1)\n",
    "        else:\n",
    "            is_conv = False\n",
    "            fc_layer0_weight_data = fc_layer0_weight.data\n",
    "            fc_layer1_weight_data = fc_layer1_weight.data\n",
    "\n",
    "        if idx == 0:\n",
    "            if is_conv:\n",
    "                M = ground_metric_object.process(fc_layer0_weight_data.view(fc_layer0_weight_data.shape[0], -1),\n",
    "                                fc_layer1_weight_data.view(fc_layer1_weight_data.shape[0], -1))\n",
    "            else:\n",
    "                M = ground_metric_object.process(fc_layer0_weight_data, fc_layer1_weight_data)\n",
    "                \n",
    "            aligned_wt = fc_layer0_weight_data\n",
    "        else:\n",
    "\n",
    "            print(\"shape of layer: model 0\", fc_layer0_weight_data.shape)\n",
    "            print(\"shape of layer: model 1\", fc_layer1_weight_data.shape)\n",
    "            print(\"shape of previous transport map\", T_var.shape)\n",
    "\n",
    "            if is_conv:\n",
    "                T_var_conv = T_var.unsqueeze(0).repeat(fc_layer0_weight_data.shape[2], 1, 1)\n",
    "                aligned_wt = torch.bmm(fc_layer0_weight_data.permute(2, 0, 1), T_var_conv).permute(1, 2, 0)\n",
    "\n",
    "                M = ground_metric_object.process(\n",
    "                    aligned_wt.contiguous().view(aligned_wt.shape[0], -1),\n",
    "                    fc_layer1_weight_data.view(fc_layer1_weight_data.shape[0], -1)\n",
    "                )\n",
    "            else:\n",
    "                if fc_layer0_weight.data.shape[1] != T_var.shape[0]:\n",
    "                    # Handles the switch from convolutional layers to fc layers\n",
    "                    fc_layer0_unflattened = fc_layer0_weight.data.view(fc_layer0_weight.shape[0], T_var.shape[0], -1).permute(2, 0, 1)\n",
    "                    aligned_wt = torch.bmm(\n",
    "                        fc_layer0_unflattened,\n",
    "                        T_var.unsqueeze(0).repeat(fc_layer0_unflattened.shape[0], 1, 1)\n",
    "                    ).permute(1, 2, 0)\n",
    "                    aligned_wt = aligned_wt.contiguous().view(aligned_wt.shape[0], -1)\n",
    "                else:\n",
    "                    # print(\"layer data (aligned) is \", aligned_wt, fc_layer1_weight_data)\n",
    "                    aligned_wt = torch.matmul(fc_layer0_weight.data, T_var)\n",
    "\n",
    "                M = ground_metric_object.process(aligned_wt, fc_layer1_weight)\n",
    "               \n",
    "            if skip_last_layer and idx == (num_layers - 1):\n",
    "                print(\"Simple averaging of last layer weights. NO transport map needs to be computed\")\n",
    "                if ensemble_step != 0.5:\n",
    "                    avg_aligned_layers.append((1 - ensemble_step) * aligned_wt +\n",
    "                                          ensemble_step * fc_layer1_weight)\n",
    "                else:\n",
    "                    avg_aligned_layers.append((aligned_wt + fc_layer1_weight)/2)\n",
    "                return avg_aligned_layers\n",
    "\n",
    "        if importance is None or (idx == num_layers -1):\n",
    "            mu = get_histogram(0, mu_cardinality, layer0_name)\n",
    "            nu = get_histogram(1, nu_cardinality, layer1_name)\n",
    "        else:\n",
    "            raise Exception(\"Deleted code\")\n",
    "\n",
    "        cpuM = M.data.cpu().numpy()\n",
    "        if exact:\n",
    "            T = ot.emd(mu, nu, cpuM)\n",
    "        else:\n",
    "            T = ot.bregman.sinkhorn(mu, nu, cpuM, reg=reg)\n",
    "\n",
    "        if GPU_USED!=-1:\n",
    "            T_var = torch.from_numpy(T).cuda(GPU_USED).float()\n",
    "        else:\n",
    "            T_var = torch.from_numpy(T).float()\n",
    "\n",
    "\n",
    "        if correction:\n",
    "            if not proper_marginals:\n",
    "                # think of it as m x 1, scaling weights for m linear combinations of points in X\n",
    "                if GPU_USED != -1:\n",
    "                    marginals = torch.ones(T_var.shape[0]).cuda(GPU_USED) / T_var.shape[0]\n",
    "                else:\n",
    "                    marginals = torch.ones(T_var.shape[0]) / T_var.shape[0]\n",
    "                marginals = torch.diag(1.0/(marginals + eps))  # take inverse\n",
    "                T_var = torch.matmul(T_var, marginals)\n",
    "            else:\n",
    "                # marginals_alpha = T_var @ torch.ones(T_var.shape[1], dtype=T_var.dtype).to(device)\n",
    "                marginals_beta = T_var.t() @ torch.ones(T_var.shape[0], dtype=T_var.dtype).to(device)\n",
    "\n",
    "                marginals = (1 / (marginals_beta + eps))\n",
    "                print(\"shape of inverse marginals beta is \", marginals_beta.shape)\n",
    "                print(\"inverse marginals beta is \", marginals_beta)\n",
    "\n",
    "                T_var = T_var * marginals\n",
    "                # i.e., how a neuron of 2nd model is constituted by the neurons of 1st model\n",
    "                # this should all be ones, and number equal to number of neurons in 2nd model\n",
    "                print(T_var.sum(dim=0))\n",
    "                # assert (T_var.sum(dim=0) == torch.ones(T_var.shape[1], dtype=T_var.dtype).to(device)).all()\n",
    "\n",
    "        #if args.debug:\n",
    "        #    if idx == (num_layers - 1):\n",
    "        #        print(\"there goes the last transport map: \\n \", T_var)\n",
    "        #    else:\n",
    "        #        print(\"there goes the transport map at layer {}: \\n \".format(idx), T_var)\n",
    "        #    print(\"Ratio of trace to the matrix sum: \", torch.trace(T_var) / torch.sum(T_var))\n",
    "\n",
    "        #print(\"Ratio of trace to the matrix sum: \", torch.trace(T_var) / torch.sum(T_var))\n",
    "        #print(\"Here, trace is {} and matrix sum is {} \".format(torch.trace(T_var), torch.sum(T_var)))\n",
    "        #setattr(args, 'trace_sum_ratio_{}'.format(layer0_name), (torch.trace(T_var) / torch.sum(T_var)).item())\n",
    "\n",
    "        if past_correction:\n",
    "            print(\"this is past correction for weight mode\")\n",
    "            print(\"Shape of aligned wt is \", aligned_wt.shape)\n",
    "            print(\"Shape of fc_layer0_weight_data is \", fc_layer0_weight_data.shape)\n",
    "            t_fc0_model = torch.matmul(T_var.t(), aligned_wt.contiguous().view(aligned_wt.shape[0], -1))\n",
    "        else:\n",
    "            t_fc0_model = torch.matmul(T_var.t(), fc_layer0_weight_data.view(fc_layer0_weight_data.shape[0], -1))\n",
    "\n",
    "        # Average the weights of aligned first layers\n",
    "        if ensemble_step != 0.5:\n",
    "            geometric_fc = ((1-ensemble_step) * t_fc0_model +\n",
    "                            ensemble_step * fc_layer1_weight_data.view(fc_layer1_weight_data.shape[0], -1))\n",
    "        else:\n",
    "            geometric_fc = (t_fc0_model + fc_layer1_weight_data.view(fc_layer1_weight_data.shape[0], -1))/2\n",
    "        if is_conv and layer_shape != geometric_fc.shape:\n",
    "            geometric_fc = geometric_fc.view(layer_shape)\n",
    "            \n",
    "        avg_aligned_layers.append(geometric_fc)\n",
    "\n",
    "        # get the performance of the model 0 aligned with respect to the model 1\n",
    "        if eval_aligned:\n",
    "            raise Exception(\"Deleted code.\")\n",
    "\n",
    "    return avg_aligned_layers"
   ],
   "metadata": {
    "id": "ZyX-TwKDFfc4",
    "ExecuteTime": {
     "start_time": "2023-05-01T15:12:52.715492Z",
     "end_time": "2023-05-01T15:12:52.787392Z"
    }
   },
   "execution_count": 13,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def test(args, network, test_loader, log_dict, debug=False, return_loss=False, is_local=False):\n",
    "    network.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    if is_local:\n",
    "        print(\"\\n--------- Testing in local mode ---------\")\n",
    "    else:\n",
    "        print(\"\\n--------- Testing in global mode ---------\")\n",
    "\n",
    "    for data, target in test_loader:\n",
    "        if GPU_USED!=-1:\n",
    "            data = data.cuda(GPU_USED)\n",
    "            target = target.cuda(GPU_USED)\n",
    "\n",
    "        output = network(data)\n",
    "        if debug:\n",
    "            print(\"output is \", output)\n",
    "\n",
    "        # mnist models return log_softmax outputs, while cifar ones return raw values!    \n",
    "        test_loss += F.nll_loss(output, target, size_average=False).item()\n",
    "\n",
    "        pred = output.data.max(1, keepdim=True)[1]\n",
    "        correct += pred.eq(target.data.view_as(pred)).sum()\n",
    "\n",
    "    print(\"size of test_loader dataset: \", len(test_loader.dataset))\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    if is_local:\n",
    "        string_info = 'local_test'\n",
    "    else:\n",
    "        string_info = 'test'\n",
    "    log_dict['{}_losses'.format(string_info)].append(test_loss)\n",
    "    print('\\nTest set: Avg. loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))\n",
    "\n",
    "    ans = (float(correct) * 100.0) / len(test_loader.dataset)\n",
    "\n",
    "    if not return_loss:\n",
    "        return ans\n",
    "    else:\n",
    "        return ans, test_loss"
   ],
   "metadata": {
    "id": "bp_NBFXCQyrn",
    "ExecuteTime": {
     "start_time": "2023-05-01T15:12:54.172004Z",
     "end_time": "2023-05-01T15:12:54.203614Z"
    }
   },
   "execution_count": 14,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def get_network_from_param_list(args, param_list, test_loader):\n",
    "\n",
    "    print(\"using independent method\")\n",
    "    new_network = MlpNet()\n",
    "    if GPU_USED != -1:\n",
    "        new_network = new_network.cuda(GPU_USED)\n",
    "\n",
    "    # check the test performance of the network before\n",
    "    log_dict = {}\n",
    "    log_dict['test_losses'] = []\n",
    "    test(args, new_network, test_loader, log_dict)\n",
    "\n",
    "    # set the weights of the new network\n",
    "    print(\"len of model parameters and avg aligned layers is \", len(list(new_network.parameters())), len(param_list))\n",
    "    assert len(list(new_network.parameters())) == len(param_list)\n",
    "\n",
    "    layer_idx = 0\n",
    "    model_state_dict = new_network.state_dict()\n",
    "\n",
    "    print(\"len of model_state_dict is \", len(model_state_dict.items()))\n",
    "    print(\"len of param_list is \", len(param_list))\n",
    "\n",
    "    for key, value in model_state_dict.items():\n",
    "        model_state_dict[key] = param_list[layer_idx]\n",
    "        layer_idx += 1\n",
    "\n",
    "    new_network.load_state_dict(model_state_dict)\n",
    "\n",
    "    # check the test performance of the network after\n",
    "    log_dict = {}\n",
    "    log_dict['test_losses'] = []\n",
    "    acc = test(args, new_network, test_loader, log_dict)\n",
    "\n",
    "    return acc, new_network"
   ],
   "metadata": {
    "id": "p1d0fb2oQchq",
    "ExecuteTime": {
     "start_time": "2023-05-01T15:12:55.883735Z",
     "end_time": "2023-05-01T15:12:55.924352Z"
    }
   },
   "execution_count": 15,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Main"
   ],
   "metadata": {
    "id": "5LxplH0w2L1k"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Custom Model A\n"
   ],
   "metadata": {
    "id": "eZkvgn8qUSrc"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "#Read the model\n",
    "model_A = MlpNet()\n",
    "model_A.load_state_dict(torch.load(\"model_A.pth\"))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cN_yiAb4w3o-",
    "outputId": "8f6567a7-ce6f-46a8-949d-795df483f33c",
    "ExecuteTime": {
     "start_time": "2023-05-01T15:12:59.359078Z",
     "end_time": "2023-05-01T15:12:59.434235Z"
    }
   },
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "<All keys matched successfully>"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Custom Model B"
   ],
   "metadata": {
    "id": "N-zjV-3AUUe4"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "model_B = MlpNet()\n",
    "model_B.load_state_dict(torch.load(\"model_B.pth\"))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zj6TQH7gw5H_",
    "outputId": "b2a2b7b5-301a-461b-e123-fc151038bf7a",
    "ExecuteTime": {
     "start_time": "2023-05-01T15:13:16.957140Z",
     "end_time": "2023-05-01T15:13:17.023175Z"
    }
   },
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "<All keys matched successfully>"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "models = [model_A, model_B]\n",
    "args = None"
   ],
   "metadata": {
    "id": "TXFKTcYXzAnu",
    "ExecuteTime": {
     "start_time": "2023-05-01T16:19:29.805927Z",
     "end_time": "2023-05-01T16:19:29.823789Z"
    }
   },
   "execution_count": 43,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Merge using Wasserstein distance on weights"
   ],
   "metadata": {
    "id": "aX9ZmDC3UXWt"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "train_loader, test_loader = get_dataloader()"
   ],
   "metadata": {
    "id": "SN2wo0v_1tSS",
    "ExecuteTime": {
     "start_time": "2023-05-01T16:19:30.130820Z",
     "end_time": "2023-05-01T16:19:30.233080Z"
    }
   },
   "execution_count": 44,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "activations = get_model_activations(None, models, config=None)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AsEkRD9P355c",
    "outputId": "7c787e08-f041-4566-c39c-29e68d56f35f",
    "ExecuteTime": {
     "start_time": "2023-05-01T16:19:30.325569Z",
     "end_time": "2023-05-01T16:19:30.753193Z"
    }
   },
   "execution_count": 45,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "excluded\n",
      "set forward hook for layer named:  fc1\n",
      "set forward hook for layer named:  fc2\n",
      "set forward hook for layer named:  fc3\n",
      "set forward hook for layer named:  fc4\n",
      "excluded\n",
      "set forward hook for layer named:  fc1\n",
      "set forward hook for layer named:  fc2\n",
      "set forward hook for layer named:  fc3\n",
      "set forward hook for layer named:  fc4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6m/f_nq8g4538s6sccmbwhx5msc0000gn/T/ipykernel_45178/818318830.py:32: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.log_softmax(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_personal_idx  25\n",
      "***********\n",
      "min of act: -2.6315741539001465, max: 2.6386382579803467, mean: -0.0048573692329227924\n",
      "***********\n",
      "min of act: -0.9510814547538757, max: 0.8703941106796265, mean: 0.002457394264638424\n",
      "***********\n",
      "min of act: -0.3619929254055023, max: 0.38994652032852173, mean: -0.0010728973429650068\n",
      "***********\n",
      "min of act: -0.09826940298080444, max: 0.1475382149219513, mean: 0.002620210638269782\n",
      "***********\n",
      "min of act: -3.4334421157836914, max: 7.080609321594238, mean: 0.5755436420440674\n",
      "***********\n",
      "min of act: -2.987900733947754, max: 10.621912956237793, mean: 0.8549277186393738\n",
      "***********\n",
      "min of act: -4.2195143699646, max: 8.599244117736816, mean: 1.068608045578003\n",
      "***********\n",
      "min of act: -10.92115592956543, max: 13.338738441467285, mean: 0.1271066814661026\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "def merge_models_wts(args, models, train_loader, test_loader, activations):\n",
    "    avg_aligned_layers = get_wassersteinized_layers_modularized(args, models, activations, test_loader=test_loader)\n",
    "    return get_network_from_param_list(args, avg_aligned_layers, test_loader)"
   ],
   "metadata": {
    "id": "uT1FOuRmFS8q",
    "ExecuteTime": {
     "start_time": "2023-05-01T16:19:30.691293Z",
     "end_time": "2023-05-01T16:19:30.753684Z"
    }
   },
   "execution_count": 46,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "geometric_acc, geometric_model = merge_models_wts(args, models, train_loader, test_loader, activations)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6KKnscyYCxoi",
    "outputId": "7112d9eb-d2ea-4e08-a694-5806c1930a3e",
    "ExecuteTime": {
     "start_time": "2023-05-01T16:19:30.729038Z",
     "end_time": "2023-05-01T16:19:41.487191Z"
    }
   },
   "execution_count": 47,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing the coordinates to form ground_metric\n",
      "dont leave off the squaring of the ground metric\n",
      "returns a uniform measure of cardinality:  400\n",
      "returns a uniform measure of cardinality:  400\n",
      "this is past correction for weight mode\n",
      "Shape of aligned wt is  torch.Size([400, 784])\n",
      "Shape of fc_layer0_weight_data is  torch.Size([400, 784])\n",
      "shape of layer: model 0 torch.Size([200, 400])\n",
      "shape of layer: model 1 torch.Size([200, 400])\n",
      "shape of previous transport map torch.Size([400, 400])\n",
      "Processing the coordinates to form ground_metric\n",
      "dont leave off the squaring of the ground metric\n",
      "returns a uniform measure of cardinality:  200\n",
      "returns a uniform measure of cardinality:  200\n",
      "this is past correction for weight mode\n",
      "Shape of aligned wt is  torch.Size([200, 400])\n",
      "Shape of fc_layer0_weight_data is  torch.Size([200, 400])\n",
      "shape of layer: model 0 torch.Size([100, 200])\n",
      "shape of layer: model 1 torch.Size([100, 200])\n",
      "shape of previous transport map torch.Size([200, 200])\n",
      "Processing the coordinates to form ground_metric\n",
      "dont leave off the squaring of the ground metric\n",
      "returns a uniform measure of cardinality:  100\n",
      "returns a uniform measure of cardinality:  100\n",
      "this is past correction for weight mode\n",
      "Shape of aligned wt is  torch.Size([100, 200])\n",
      "Shape of fc_layer0_weight_data is  torch.Size([100, 200])\n",
      "shape of layer: model 0 torch.Size([10, 100])\n",
      "shape of layer: model 1 torch.Size([10, 100])\n",
      "shape of previous transport map torch.Size([100, 100])\n",
      "Processing the coordinates to form ground_metric\n",
      "dont leave off the squaring of the ground metric\n",
      "returns a uniform measure of cardinality:  10\n",
      "returns a uniform measure of cardinality:  10\n",
      "this is past correction for weight mode\n",
      "Shape of aligned wt is  torch.Size([10, 100])\n",
      "Shape of fc_layer0_weight_data is  torch.Size([10, 100])\n",
      "using independent method\n",
      "\n",
      "--------- Testing in global mode ---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6m/f_nq8g4538s6sccmbwhx5msc0000gn/T/ipykernel_45178/818318830.py:32: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.log_softmax(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of test_loader dataset:  10000\n",
      "\n",
      "Test set: Avg. loss: 2.3056, Accuracy: 686/10000 (7%)\n",
      "\n",
      "len of model parameters and avg aligned layers is  4 4\n",
      "len of model_state_dict is  4\n",
      "len of param_list is  4\n",
      "\n",
      "--------- Testing in global mode ---------\n",
      "size of test_loader dataset:  10000\n",
      "\n",
      "Test set: Avg. loss: 1.9742, Accuracy: 8097/10000 (81%)\n",
      "\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Vanilla Ensembling\n"
   ],
   "metadata": {
    "id": "To4dO5RyS127"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def get_avg_parameters(networks, weights=None):\n",
    "    avg_pars = []\n",
    "    for par_group in zip(*[net.parameters() for net in networks]):\n",
    "        if weights is not None:\n",
    "            weighted_par_group = [par * weights[i] for i, par in enumerate(par_group)]\n",
    "            avg_par = torch.sum(torch.stack(weighted_par_group), dim=0)\n",
    "        else:\n",
    "            avg_par = torch.mean(torch.stack(par_group), dim=0)\n",
    "        avg_pars.append(avg_par)\n",
    "    return avg_pars"
   ],
   "metadata": {
    "id": "mr2WDUc7S7N4",
    "ExecuteTime": {
     "start_time": "2023-05-01T16:19:41.497349Z",
     "end_time": "2023-05-01T16:19:41.516789Z"
    }
   },
   "execution_count": 48,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def naive_ensembling(args, networks, test_loader):\n",
    "    # simply average the weights in networks\n",
    "    \n",
    "    if width_ratio != 1:\n",
    "        print(\"Unfortunately naive ensembling can't work if models are not of same shape!\")\n",
    "        return -1, None\n",
    "    weights = [(1-ensemble_step), ensemble_step]\n",
    "    avg_pars = get_avg_parameters(networks, weights)\n",
    "    ensemble_network = MlpNet()\n",
    "    # put on GPU\n",
    "    if GPU_USED!=-1:\n",
    "        ensemble_network = ensemble_network.cuda(GPU_USED)\n",
    "\n",
    "    # check the test performance of the method before\n",
    "    log_dict = {}\n",
    "    log_dict['test_losses'] = []\n",
    "    test(args, ensemble_network, test_loader, log_dict)\n",
    "\n",
    "    # set the weights of the ensembled network\n",
    "    for idx, (name, param) in enumerate(ensemble_network.state_dict().items()):\n",
    "        ensemble_network.state_dict()[name].copy_(avg_pars[idx].data)\n",
    "\n",
    "    # check the test performance of the method after ensembling\n",
    "    log_dict = {}\n",
    "    log_dict['test_losses'] = []\n",
    "    \n",
    "    return test(args, ensemble_network, test_loader, log_dict), ensemble_network"
   ],
   "metadata": {
    "id": "VrSa7ZMjS3wu",
    "ExecuteTime": {
     "start_time": "2023-05-01T16:19:41.517156Z",
     "end_time": "2023-05-01T16:19:41.540440Z"
    }
   },
   "execution_count": 49,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "vanilla_acc, vanilla_ensemble_model = naive_ensembling(args, models, test_loader)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_Cb9smxiS-x3",
    "outputId": "4b850bce-3616-4077-ed6c-8ff25469db4e",
    "ExecuteTime": {
     "start_time": "2023-05-01T16:19:41.533274Z",
     "end_time": "2023-05-01T16:19:46.922987Z"
    }
   },
   "execution_count": 50,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------- Testing in global mode ---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6m/f_nq8g4538s6sccmbwhx5msc0000gn/T/ipykernel_45178/818318830.py:32: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.log_softmax(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of test_loader dataset:  10000\n",
      "\n",
      "Test set: Avg. loss: 2.3044, Accuracy: 810/10000 (8%)\n",
      "\n",
      "\n",
      "--------- Testing in global mode ---------\n",
      "size of test_loader dataset:  10000\n",
      "\n",
      "Test set: Avg. loss: 2.0564, Accuracy: 5212/10000 (52%)\n",
      "\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Results"
   ],
   "metadata": {
    "id": "TE5LDQJtVKwy"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "geometric_acc"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1xwYAdeqVOmV",
    "outputId": "b1d72039-b65d-48a6-d8ec-3c026d1cc932",
    "ExecuteTime": {
     "start_time": "2023-05-01T16:19:46.916891Z",
     "end_time": "2023-05-01T16:19:46.924043Z"
    }
   },
   "execution_count": 51,
   "outputs": [
    {
     "data": {
      "text/plain": "80.97"
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "vanilla_acc"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SUBYMAbYVQKi",
    "outputId": "3edfec80-8500-41ee-90f4-f33118508cf9",
    "ExecuteTime": {
     "start_time": "2023-05-01T16:19:46.925392Z",
     "end_time": "2023-05-01T16:19:46.939836Z"
    }
   },
   "execution_count": 52,
   "outputs": [
    {
     "data": {
      "text/plain": "52.12"
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ]
}
