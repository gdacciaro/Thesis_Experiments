{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Experiment 1\n"
      ],
      "metadata": {
        "id": "szQteeChtEVH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup"
      ],
      "metadata": {
        "id": "81cipUPKtHNu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade --no-cache-dir gdown &> /dev/null\n",
        "!pip install --upgrade --no-cache-dir POT &> /dev/null\n",
        "!pip uninstall torch -y &> /dev/null\n",
        "!pip install torch==1.13.1 &> /dev/null"
      ],
      "metadata": {
        "id": "JZ9PmEjluO_O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qbLzOInfnCag",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8df03d5e-b054-4a53-e904-221d0ee6e347"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/usr/local/lib/python3.9/dist-packages/torchvision/image.so: undefined symbol: _ZN3c104cuda20CUDACachingAllocator9allocatorE'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
            "  warn(\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import ot\n",
        "import time\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "import torchvision "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Pytorch version is \", torch.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f--1uFjV1ap-",
        "outputId": "05851b79-cb13-49e7-e62d-7edb37fb999f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pytorch version is  1.13.1+cu117\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Constants\n",
        "NUMPY_SEED = 100\n",
        "np.random.seed(NUMPY_SEED)\n",
        "\n",
        "GPU_USED = -1 # -1 = CPU"
      ],
      "metadata": {
        "id": "k6YV1DYcve4f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Args\n",
        "batch_size_train = 64\n",
        "batch_size_test = 1000\n",
        "activation_histograms = True\n",
        "act_num_samples = 200\n",
        "activation_mode = \"raw\"\n",
        "activation_seed = 21\n",
        "disable_bias = True\n",
        "personal_class_idx = 9\n",
        "prelu_acts = True\n",
        "unbalanced = False\n",
        "importance = None\n",
        "exact = False #OT Exact mode\n",
        "ensemble_step = 0.5\n",
        "eval_aligned = False\n",
        "softmax_temperature = 1\n",
        "past_correction = True\n",
        "skip_last_layer = False\n",
        "reg = 0.01\n",
        "correction = True\n",
        "proper_marginals = False\n",
        "width_ratio = 1\n",
        "\n",
        "ground_metric = 'euclidean'\n",
        "ground_metric_normalize = 'none'\n",
        "ground_metric_eff = False\n",
        "not_squared = True\n",
        "geom_ensemble_type = \"acts\"\n",
        "normalize_wts = False\n",
        "clip_gm = False\n",
        "\n",
        "ground_metric_params = {\n",
        "    \"ground_metric\": ground_metric,\n",
        "    \"reg\": reg,\n",
        "    \"ground_metric_normalize\": ground_metric_normalize,\n",
        "    \"ground_metric_eff\": ground_metric_eff,\n",
        "    \"not_squared\": not_squared,\n",
        "    \"geom_ensemble_type\": geom_ensemble_type,\n",
        "    \"normalize_wts\":normalize_wts,\n",
        "    \"clip_gm\":clip_gm\n",
        "}"
      ],
      "metadata": {
        "id": "bLbhyifO2qa3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download and unzip MNIST models\n",
        "mnist_models_fileid = \"1SJTxBpi2Ln3XukcJLJNFIv8S2ix_M2sp\"\n",
        "!gdown $mnist_models_fileid \n",
        "!rm -rf mnist_models\n",
        "!unzip mnist_models.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MMf3oUktt4DQ",
        "outputId": "1cb367af-6c65-4746-e413-297d5bbb1f20"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1SJTxBpi2Ln3XukcJLJNFIv8S2ix_M2sp\n",
            "To: /content/mnist_models.zip\n",
            "\r  0% 0.00/3.07M [00:00<?, ?B/s]\r100% 3.07M/3.07M [00:00<00:00, 46.9MB/s]\n",
            "Archive:  mnist_models.zip\n",
            "   creating: mnist_models/\n",
            "   creating: mnist_models/mnsit/\n",
            "   creating: mnist_models/model_0/\n",
            "   creating: mnist_models/model_1/\n",
            "  inflating: mnist_models/model_0/final.checkpoint  \n",
            "  inflating: mnist_models/model_1/final.checkpoint  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Functions from original code"
      ],
      "metadata": {
        "id": "u7VrEocvvmtR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MlpNet(nn.Module):\n",
        "    def __init__(self, width_ratio=-1):\n",
        "        super(MlpNet, self).__init__()\n",
        "        input_dim = 784 # [mnist] 28 x 28 x 1\n",
        "        if width_ratio != -1:\n",
        "            self.width_ratio = width_ratio\n",
        "        else:\n",
        "            self.width_ratio = 1\n",
        "\n",
        "        self.fc1 = nn.Linear(input_dim, int(400/self.width_ratio), bias=not True)\n",
        "        self.fc2 = nn.Linear(int(400/self.width_ratio), int(200/self.width_ratio), bias=not True)\n",
        "        self.fc3 = nn.Linear(int(200/self.width_ratio), int(100/self.width_ratio), bias=not True)\n",
        "        self.fc4 = nn.Linear(int(100/self.width_ratio), 10, bias=not True)\n",
        "        self.enable_dropout = False\n",
        "\n",
        "    def forward(self, x, disable_logits=False):\n",
        "        x = x.view(x.shape[0], -1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        if self.enable_dropout:\n",
        "            x = F.dropout(x, training=self.training)\n",
        "        x = F.relu(self.fc2(x))\n",
        "        if self.enable_dropout:\n",
        "            x = F.dropout(x, training=self.training)\n",
        "        x = F.relu(self.fc3(x))\n",
        "        if self.enable_dropout:\n",
        "            x = F.dropout(x, training=self.training)\n",
        "        x = self.fc4(x)\n",
        "\n",
        "        if disable_logits:\n",
        "            return x\n",
        "        else:\n",
        "            return F.log_softmax(x)"
      ],
      "metadata": {
        "id": "TETefZEOv3kK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_pretrained_model(path, data_separated=False):\n",
        "    model = MlpNet()\n",
        "\n",
        "    \n",
        "    if GPU_USED != -1:\n",
        "        state = torch.load(\n",
        "            path, map_location=(\n",
        "                lambda s, _: torch.serialization.default_restore_location(s, 'cuda:' + str(GPU_USED))\n",
        "            ),)\n",
        "    else:\n",
        "        state = torch.load(\n",
        "            path, map_location=(\n",
        "                lambda s, _: torch.serialization.default_restore_location(s, 'cpu')\n",
        "            ),)\n",
        "\n",
        "    model_state_dict = state['model_state_dict']\n",
        "\n",
        "    if 'test_accuracy' not in state:\n",
        "        state['test_accuracy'] = -1\n",
        "\n",
        "    if 'epoch' not in state:\n",
        "        state['epoch'] = -1\n",
        "\n",
        "    if not data_separated:\n",
        "        print(\"Loading model at path {} which had accuracy {} and at epoch {}\".format(path, state['test_accuracy'],\n",
        "                                                                                  state['epoch']))\n",
        "    else:\n",
        "        print(\"Loading model at path {} which had local accuracy {} and overall accuracy {} for choice {} at epoch {}\".format(path,\n",
        "            state['local_test_accuracy'], state['test_accuracy'], state['choice'], state['epoch']))\n",
        "\n",
        "    model.load_state_dict(model_state_dict)\n",
        "\n",
        "    if GPU_USED != -1:\n",
        "        model = model.cuda(GPU_USED)\n",
        "\n",
        "    if not data_separated:\n",
        "        return model, state['test_accuracy']\n",
        "    else:\n",
        "        return model, state['test_accuracy'], state['local_test_accuracy']\n"
      ],
      "metadata": {
        "id": "W3vce6quvqnx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_dataloader(unit_batch = False, no_randomness=False):\n",
        "    if unit_batch:\n",
        "        bsz = (1, 1)\n",
        "    else:\n",
        "        bsz = (batch_size_train, batch_size_test)\n",
        "\n",
        "    if no_randomness:\n",
        "        enable_shuffle = False\n",
        "    else:\n",
        "        enable_shuffle = True\n",
        "        \n",
        "    train_loader = torch.utils.data.DataLoader(\n",
        "          torchvision.datasets.MNIST('./files/', train=True, download=True,\n",
        "                                     transform=torchvision.transforms.Compose([\n",
        "                                       torchvision.transforms.ToTensor(),\n",
        "                                       torchvision.transforms.Normalize(\n",
        "                                           # only 1 channel\n",
        "                                           (0.1307,), (0.3081,))\n",
        "                                     ])),\n",
        "          batch_size=bsz[0], shuffle=enable_shuffle\n",
        "        )\n",
        "\n",
        "\n",
        "    test_loader = torch.utils.data.DataLoader(\n",
        "          torchvision.datasets.MNIST('./files/', train=False, download=True,\n",
        "                 transform=torchvision.transforms.Compose([\n",
        "                   torchvision.transforms.ToTensor(),\n",
        "                   torchvision.transforms.Normalize(\n",
        "                       (0.1307,), (0.3081,))\n",
        "                 ])),\n",
        "          batch_size=bsz[1], shuffle=enable_shuffle\n",
        "        )\n",
        "\n",
        "    return train_loader, test_loader\n"
      ],
      "metadata": {
        "id": "ocSFvHx-2NKN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_activations_across_models_v1(args, models, train_loader, num_samples, mode='mean',\n",
        "                                         dump_activations=False, dump_path=None):\n",
        "    torch.manual_seed(activation_seed)\n",
        "\n",
        "    # hook that computes the mean activations across data samples\n",
        "    def get_activation(activation, name):\n",
        "        def hook(model, input, output):\n",
        "            if name not in activation:\n",
        "                activation[name] = []\n",
        "\n",
        "            activation[name].append(output.detach())\n",
        "\n",
        "        return hook\n",
        "\n",
        "    # Prepare all the models\n",
        "    activations = {}\n",
        "    forward_hooks = []\n",
        "\n",
        "    assert disable_bias\n",
        "    # handle below for bias later on!\n",
        "    # print(\"list of model named params \", list(models[0].named_parameters()))\n",
        "    param_names = [tupl[0].replace('.weight', '') for tupl in models[0].named_parameters()]\n",
        "    for idx, model in enumerate(models):\n",
        "\n",
        "        # Initialize the activation dictionary for each model\n",
        "        activations[idx] = {}\n",
        "        layer_hooks = []\n",
        "        # Set forward hooks for all layers inside a model\n",
        "        for name, layer in model.named_modules():\n",
        "            if name == '':\n",
        "                print(\"excluded\")\n",
        "                continue\n",
        "            layer_hooks.append(layer.register_forward_hook(get_activation(activations[idx], name)))\n",
        "            print(\"set forward hook for layer named: \", name)\n",
        "\n",
        "        forward_hooks.append(layer_hooks)\n",
        "        # Set the model in train mode\n",
        "        model.train()\n",
        "\n",
        "    # Run the same data samples ('num_samples' many) across all the models\n",
        "    num_samples_processed = 0\n",
        "    num_personal_idx = 0\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        if num_samples_processed == num_samples:\n",
        "            break\n",
        "\n",
        "        if GPU_USED != -1:\n",
        "            data = data.cuda(GPU_USED)\n",
        "\n",
        "        if int(target.item()) == personal_class_idx:\n",
        "            num_personal_idx += 1\n",
        "\n",
        "        for idx, model in enumerate(models):\n",
        "            model(data)\n",
        "\n",
        "        num_samples_processed += 1\n",
        "\n",
        "    print(\"num_personal_idx \", num_personal_idx)\n",
        "\n",
        "    relu = torch.nn.ReLU()\n",
        "    maxpool = torch.nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "    avgpool = torch.nn.AvgPool2d(kernel_size=1, stride=1)\n",
        "\n",
        "    # Combine the activations generated across the number of samples to form importance scores\n",
        "    # The importance calculated is based on the 'mode' flag: which is either of 'mean', 'std', 'meanstd'\n",
        "\n",
        "    model_cfg = None\n",
        "    for idx in range(len(models)):\n",
        "        cfg_idx = 0\n",
        "        for lnum, layer in enumerate(activations[idx]):\n",
        "            print('***********')\n",
        "            activations[idx][layer] = torch.stack(activations[idx][layer])\n",
        "            print(\"min of act: {}, max: {}, mean: {}\".format(torch.min(activations[idx][layer]), torch.max(activations[idx][layer]), torch.mean(activations[idx][layer])))\n",
        "            if not prelu_acts and not lnum == (len(activations[idx])-1):\n",
        "                # print(\"activation was \", activations[idx][layer])\n",
        "                print(\"applying relu ---------------\")\n",
        "                activations[idx][layer] = relu(activations[idx][layer])\n",
        "                print(\"after RELU: min of act: {}, max: {}, mean: {}\".format(torch.min(activations[idx][layer]),\n",
        "                                                                 torch.max(activations[idx][layer]),\n",
        "                                                                 torch.mean(activations[idx][layer])))\n",
        "            if mode == 'mean':\n",
        "                activations[idx][layer] = activations[idx][layer].mean(dim=0)\n",
        "            elif mode == 'std':\n",
        "                activations[idx][layer] = activations[idx][layer].std(dim=0)\n",
        "            elif mode == 'meanstd':\n",
        "                activations[idx][layer] = activations[idx][layer].mean(dim=0) * activations[idx][layer].std(dim=0)\n",
        "\n",
        "    # Remove the hooks (as this was intefering with prediction ensembling)\n",
        "    for idx in range(len(forward_hooks)):\n",
        "        for hook in forward_hooks[idx]:\n",
        "            hook.remove()\n",
        "\n",
        "    return activations"
      ],
      "metadata": {
        "id": "FSXbSR9jAFhX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_model_activations(args, models, config=None, layer_name=None, selective=False, personal_dataset = None):\n",
        "    train_loader, test_loader = get_dataloader(unit_batch=True)\n",
        "    activations = compute_activations_across_models_v1(args, models,\n",
        "                                                          train_loader,\n",
        "                                                          act_num_samples,\n",
        "                                                          mode=activation_mode)\n",
        "    return activations\n",
        "                "
      ],
      "metadata": {
        "id": "M3pdTa9d4QAa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "class GroundMetric:\n",
        "    \"\"\"\n",
        "        Ground Metric object for Wasserstein computations:\n",
        "\n",
        "    \"\"\"\n",
        "    def isnan(self,x):\n",
        "      return x != x\n",
        "\n",
        "    def __init__(self, params, not_squared = False):\n",
        "        self.params = params\n",
        "        self.ground_metric_type = params[\"ground_metric\"]\n",
        "        self.ground_metric_normalize = params[\"ground_metric_normalize\"]\n",
        "        self.reg = params[\"reg\"]\n",
        "        self.squared = False\n",
        "        self.mem_eff = params[\"ground_metric_eff\"]\n",
        "\n",
        "    def _clip(self, ground_metric_matrix):\n",
        "        if self.params[\"debug\"]:\n",
        "            print(\"before clipping\", ground_metric_matrix.data)\n",
        "\n",
        "        percent_clipped = (float((ground_metric_matrix >= self.reg * self.params.clip_max).long().sum().data) \\\n",
        "                           / ground_metric_matrix.numel()) * 100\n",
        "        print(\"percent_clipped is (assumes clip_min = 0) \", percent_clipped)\n",
        "        #setattr(self.params, 'percent_clipped', percent_clipped)\n",
        "        # will keep the M' = M/reg in range clip_min and clip_max\n",
        "        ground_metric_matrix.clamp_(min=self.reg * self.params.clip_min,\n",
        "                                             max=self.reg * self.params.clip_max)\n",
        "        if self.params[\"debug\"]:\n",
        "            print(\"after clipping\", ground_metric_matrix.data)\n",
        "        return ground_metric_matrix\n",
        "\n",
        "    def _normalize(self, ground_metric_matrix):\n",
        "\n",
        "        if self.ground_metric_normalize == \"log\":\n",
        "            ground_metric_matrix = torch.log1p(ground_metric_matrix)\n",
        "        elif self.ground_metric_normalize == \"max\":\n",
        "            print(\"Normalizing by max of ground metric and which is \", ground_metric_matrix.max())\n",
        "            ground_metric_matrix = ground_metric_matrix / ground_metric_matrix.max()\n",
        "        elif self.ground_metric_normalize == \"median\":\n",
        "            print(\"Normalizing by median of ground metric and which is \", ground_metric_matrix.median())\n",
        "            ground_metric_matrix = ground_metric_matrix / ground_metric_matrix.median()\n",
        "        elif self.ground_metric_normalize == \"mean\":\n",
        "            print(\"Normalizing by mean of ground metric and which is \", ground_metric_matrix.mean())\n",
        "            ground_metric_matrix = ground_metric_matrix / ground_metric_matrix.mean()\n",
        "        elif self.ground_metric_normalize == \"none\":\n",
        "            return ground_metric_matrix\n",
        "        else:\n",
        "            raise NotImplementedError\n",
        "\n",
        "        return ground_metric_matrix\n",
        "\n",
        "    def _sanity_check(self, ground_metric_matrix):\n",
        "        assert not (ground_metric_matrix < 0).any()\n",
        "        assert not (self.isnan(ground_metric_matrix).any())\n",
        "\n",
        "    def _cost_matrix_xy(self, x, y, p=2, squared = True):\n",
        "        # TODO: Use this to guarantee reproducibility of previous results and then move onto better way\n",
        "        \"Returns the matrix of $|x_i-y_j|^p$.\"\n",
        "        x_col = x.unsqueeze(1)\n",
        "        y_lin = y.unsqueeze(0)\n",
        "        c = torch.sum((torch.abs(x_col - y_lin)) ** p, 2)\n",
        "        if not squared:\n",
        "            print(\"dont leave off the squaring of the ground metric\")\n",
        "            c = c ** (1/2)\n",
        "        return c\n",
        "\n",
        "\n",
        "    def _pairwise_distances(self, x, y=None, squared=True):\n",
        "        '''\n",
        "        Source: https://discuss.pytorch.org/t/efficient-distance-matrix-computation/9065/2\n",
        "        Input: x is a Nxd matrix\n",
        "               y is an optional Mxd matirx\n",
        "        Output: dist is a NxM matrix where dist[i,j] is the square norm between x[i,:] and y[j,:]\n",
        "                if y is not given then use 'y=x'.\n",
        "        i.e. dist[i,j] = ||x[i,:]-y[j,:]||^2\n",
        "        '''\n",
        "        x_norm = (x ** 2).sum(1).view(-1, 1)\n",
        "        if y is not None:\n",
        "            y_t = torch.transpose(y, 0, 1)\n",
        "            y_norm = (y ** 2).sum(1).view(1, -1)\n",
        "        else:\n",
        "            y_t = torch.transpose(x, 0, 1)\n",
        "            y_norm = x_norm.view(1, -1)\n",
        "\n",
        "        dist = x_norm + y_norm - 2.0 * torch.mm(x, y_t)\n",
        "        # Ensure diagonal is zero if x=y\n",
        "        dist = torch.clamp(dist, min=0.0)\n",
        "\n",
        "        if self.params.activation_histograms and self.params.dist_normalize:\n",
        "            dist = dist/self.params.act_num_samples\n",
        "            print(\"Divide squared distances by the num samples\")\n",
        "\n",
        "        if not squared:\n",
        "            print(\"dont leave off the squaring of the ground metric\")\n",
        "            dist = dist ** (1/2)\n",
        "\n",
        "        return dist\n",
        "\n",
        "    def _get_euclidean(self, coordinates, other_coordinates=None):\n",
        "        # TODO: Replace by torch.pdist (which is said to be much more memory efficient)\n",
        "\n",
        "        if other_coordinates is None:\n",
        "            matrix = torch.norm(\n",
        "                coordinates.view(coordinates.shape[0], 1, coordinates.shape[1]) \\\n",
        "                - coordinates, p=2, dim=2\n",
        "            )\n",
        "        else:\n",
        "            if self.mem_eff:\n",
        "                matrix = self._pairwise_distances(coordinates, other_coordinates, squared=self.squared)\n",
        "            else:\n",
        "                matrix = self._cost_matrix_xy(coordinates, other_coordinates, squared = self.squared)\n",
        "\n",
        "        return matrix\n",
        "\n",
        "    def _normed_vecs(self, vecs, eps=1e-9):\n",
        "        norms = torch.norm(vecs, dim=-1, keepdim=True)\n",
        "        print(\"stats of vecs are: mean {}, min {}, max {}, std {}\".format(\n",
        "            norms.mean(), norms.min(), norms.max(), norms.std()\n",
        "        ))\n",
        "        return vecs / (norms + eps)\n",
        "\n",
        "    def _get_cosine(self, coordinates, other_coordinates=None):\n",
        "        if other_coordinates is None:\n",
        "            matrix = coordinates / torch.norm(coordinates, dim=1, keepdim=True)\n",
        "            matrix = 1 - matrix @ matrix.t()\n",
        "        else:\n",
        "            matrix = 1 - torch.div(\n",
        "                coordinates @ other_coordinates.t(),\n",
        "                torch.norm(coordinates, dim=1).view(-1, 1) @ torch.norm(other_coordinates, dim=1).view(1, -1)\n",
        "            )\n",
        "        return matrix.clamp_(min=0)\n",
        "\n",
        "    def _get_angular(self, coordinates, other_coordinates=None):\n",
        "        pass\n",
        "\n",
        "    def get_metric(self, coordinates, other_coordinates=None):\n",
        "        get_metric_map = {\n",
        "            'euclidean': self._get_euclidean,\n",
        "            'cosine': self._get_cosine,\n",
        "            'angular': self._get_angular,\n",
        "        }\n",
        "        return get_metric_map[self.ground_metric_type](coordinates, other_coordinates)\n",
        "\n",
        "    def process(self, coordinates, other_coordinates=None):\n",
        "        print('Processing the coordinates to form ground_metric')\n",
        "        if self.params[\"geom_ensemble_type\"] == 'wts' and self.params[\"normalize_wts\"]:\n",
        "            print(\"In weight mode: normalizing weights to unit norm\")\n",
        "            coordinates = self._normed_vecs(coordinates)\n",
        "            if other_coordinates is not None:\n",
        "                other_coordinates = self._normed_vecs(other_coordinates)\n",
        "\n",
        "        ground_metric_matrix = self.get_metric(coordinates, other_coordinates)\n",
        "\n",
        "        self._sanity_check(ground_metric_matrix)\n",
        "\n",
        "        ground_metric_matrix = self._normalize(ground_metric_matrix)\n",
        "\n",
        "        self._sanity_check(ground_metric_matrix)\n",
        "\n",
        "        if self.params[\"clip_gm\"]:\n",
        "            ground_metric_matrix = self._clip(ground_metric_matrix)\n",
        "\n",
        "        self._sanity_check(ground_metric_matrix)\n",
        "\n",
        "        return ground_metric_matrix"
      ],
      "metadata": {
        "id": "8NELekZpFkJ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_histogram(idx, cardinality, layer_name, activations=None, return_numpy = True, float64=False):\n",
        "    if activations is None:\n",
        "        # returns a uniform measure\n",
        "        if not unbalanced:\n",
        "            print(\"returns a uniform measure of cardinality: \", cardinality)\n",
        "            return np.ones(cardinality)/cardinality\n",
        "        else:\n",
        "            return np.ones(cardinality)\n",
        "    else:\n",
        "        # return softmax over the activations raised to a temperature\n",
        "        # layer_name is like 'fc1.weight', while activations only contains 'fc1'\n",
        "        print(activations[idx].keys())\n",
        "        unnormalized_weights = activations[idx][layer_name.split('.')[0]]\n",
        "        print(\"For layer {},  shape of unnormalized weights is \".format(layer_name), unnormalized_weights.shape)\n",
        "        unnormalized_weights = unnormalized_weights.squeeze()\n",
        "        assert unnormalized_weights.shape[0] == cardinality\n",
        "\n",
        "        if return_numpy:\n",
        "            if float64:\n",
        "                return torch.softmax(unnormalized_weights / softmax_temperature, dim=0).data.cpu().numpy().astype(\n",
        "                    np.float64)\n",
        "            else:\n",
        "                return torch.softmax(unnormalized_weights / softmax_temperature, dim=0).data.cpu().numpy()\n",
        "        else:\n",
        "            return torch.softmax(unnormalized_weights / softmax_temperature, dim=0)"
      ],
      "metadata": {
        "id": "SaUyDUqMGNcm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_wassersteinized_layers_modularized(args, networks, activations=None, eps=1e-7, test_loader=None):\n",
        "    '''\n",
        "    Two neural networks that have to be averaged in geometric manner (i.e. layerwise).\n",
        "    The 1st network is aligned with respect to the other via wasserstein distance.\n",
        "    Also this assumes that all the layers are either fully connected or convolutional *(with no bias)*\n",
        "\n",
        "    :param networks: list of networks\n",
        "    :param activations: If not None, use it to build the activation histograms.\n",
        "    Otherwise assumes uniform distribution over neurons in a layer.\n",
        "    :return: list of layer weights 'wassersteinized'\n",
        "    '''\n",
        "\n",
        "    avg_aligned_layers = []\n",
        "    T_var = None\n",
        "    previous_layer_shape = None\n",
        "    ground_metric_object = GroundMetric(ground_metric_params)\n",
        "\n",
        "    if eval_aligned:\n",
        "        model0_aligned_layers = []\n",
        "\n",
        "    if GPU_USED==-1:\n",
        "        device = torch.device('cpu')\n",
        "    else:\n",
        "        device = torch.device('cuda:{}'.format(GPU_USED))\n",
        "\n",
        "\n",
        "    num_layers = len(list(zip(networks[0].parameters(), networks[1].parameters())))\n",
        "    for idx, ((layer0_name, fc_layer0_weight), (layer1_name, fc_layer1_weight)) in \\\n",
        "            enumerate(zip(networks[0].named_parameters(), networks[1].named_parameters())):\n",
        "\n",
        "        assert fc_layer0_weight.shape == fc_layer1_weight.shape\n",
        "        previous_layer_shape = fc_layer1_weight.shape\n",
        "\n",
        "        mu_cardinality = fc_layer0_weight.shape[0]\n",
        "        nu_cardinality = fc_layer1_weight.shape[0]\n",
        "\n",
        "        layer_shape = fc_layer0_weight.shape\n",
        "        if len(layer_shape) > 2:\n",
        "            is_conv = True\n",
        "            # For convolutional layers, it is (#out_channels, #in_channels, height, width)\n",
        "            fc_layer0_weight_data = fc_layer0_weight.data.view(fc_layer0_weight.shape[0], fc_layer0_weight.shape[1], -1)\n",
        "            fc_layer1_weight_data = fc_layer1_weight.data.view(fc_layer1_weight.shape[0], fc_layer1_weight.shape[1], -1)\n",
        "        else:\n",
        "            is_conv = False\n",
        "            fc_layer0_weight_data = fc_layer0_weight.data\n",
        "            fc_layer1_weight_data = fc_layer1_weight.data\n",
        "\n",
        "        if idx == 0:\n",
        "            if is_conv:\n",
        "                M = ground_metric_object.process(fc_layer0_weight_data.view(fc_layer0_weight_data.shape[0], -1),\n",
        "                                fc_layer1_weight_data.view(fc_layer1_weight_data.shape[0], -1))\n",
        "            else:\n",
        "                M = ground_metric_object.process(fc_layer0_weight_data, fc_layer1_weight_data)\n",
        "                \n",
        "            aligned_wt = fc_layer0_weight_data\n",
        "        else:\n",
        "\n",
        "            print(\"shape of layer: model 0\", fc_layer0_weight_data.shape)\n",
        "            print(\"shape of layer: model 1\", fc_layer1_weight_data.shape)\n",
        "            print(\"shape of previous transport map\", T_var.shape)\n",
        "\n",
        "            if is_conv:\n",
        "                T_var_conv = T_var.unsqueeze(0).repeat(fc_layer0_weight_data.shape[2], 1, 1)\n",
        "                aligned_wt = torch.bmm(fc_layer0_weight_data.permute(2, 0, 1), T_var_conv).permute(1, 2, 0)\n",
        "\n",
        "                M = ground_metric_object.process(\n",
        "                    aligned_wt.contiguous().view(aligned_wt.shape[0], -1),\n",
        "                    fc_layer1_weight_data.view(fc_layer1_weight_data.shape[0], -1)\n",
        "                )\n",
        "            else:\n",
        "                if fc_layer0_weight.data.shape[1] != T_var.shape[0]:\n",
        "                    # Handles the switch from convolutional layers to fc layers\n",
        "                    fc_layer0_unflattened = fc_layer0_weight.data.view(fc_layer0_weight.shape[0], T_var.shape[0], -1).permute(2, 0, 1)\n",
        "                    aligned_wt = torch.bmm(\n",
        "                        fc_layer0_unflattened,\n",
        "                        T_var.unsqueeze(0).repeat(fc_layer0_unflattened.shape[0], 1, 1)\n",
        "                    ).permute(1, 2, 0)\n",
        "                    aligned_wt = aligned_wt.contiguous().view(aligned_wt.shape[0], -1)\n",
        "                else:\n",
        "                    # print(\"layer data (aligned) is \", aligned_wt, fc_layer1_weight_data)\n",
        "                    aligned_wt = torch.matmul(fc_layer0_weight.data, T_var)\n",
        "\n",
        "                M = ground_metric_object.process(aligned_wt, fc_layer1_weight)\n",
        "               \n",
        "            if skip_last_layer and idx == (num_layers - 1):\n",
        "                print(\"Simple averaging of last layer weights. NO transport map needs to be computed\")\n",
        "                if ensemble_step != 0.5:\n",
        "                    avg_aligned_layers.append((1 - ensemble_step) * aligned_wt +\n",
        "                                          ensemble_step * fc_layer1_weight)\n",
        "                else:\n",
        "                    avg_aligned_layers.append((aligned_wt + fc_layer1_weight)/2)\n",
        "                return avg_aligned_layers\n",
        "\n",
        "        if importance is None or (idx == num_layers -1):\n",
        "            mu = get_histogram(0, mu_cardinality, layer0_name)\n",
        "            nu = get_histogram(1, nu_cardinality, layer1_name)\n",
        "        else:\n",
        "            raise Exception(\"Deleted code\")\n",
        "\n",
        "        cpuM = M.data.cpu().numpy()\n",
        "        if exact:\n",
        "            T = ot.emd(mu, nu, cpuM)\n",
        "        else:\n",
        "            T = ot.bregman.sinkhorn(mu, nu, cpuM, reg=reg)\n",
        "\n",
        "        if GPU_USED!=-1:\n",
        "            T_var = torch.from_numpy(T).cuda(GPU_USED).float()\n",
        "        else:\n",
        "            T_var = torch.from_numpy(T).float()\n",
        "\n",
        "\n",
        "        if correction:\n",
        "            if not proper_marginals:\n",
        "                # think of it as m x 1, scaling weights for m linear combinations of points in X\n",
        "                if GPU_USED != -1:\n",
        "                    marginals = torch.ones(T_var.shape[0]).cuda(GPU_USED) / T_var.shape[0]\n",
        "                else:\n",
        "                    marginals = torch.ones(T_var.shape[0]) / T_var.shape[0]\n",
        "                marginals = torch.diag(1.0/(marginals + eps))  # take inverse\n",
        "                T_var = torch.matmul(T_var, marginals)\n",
        "            else:\n",
        "                # marginals_alpha = T_var @ torch.ones(T_var.shape[1], dtype=T_var.dtype).to(device)\n",
        "                marginals_beta = T_var.t() @ torch.ones(T_var.shape[0], dtype=T_var.dtype).to(device)\n",
        "\n",
        "                marginals = (1 / (marginals_beta + eps))\n",
        "                print(\"shape of inverse marginals beta is \", marginals_beta.shape)\n",
        "                print(\"inverse marginals beta is \", marginals_beta)\n",
        "\n",
        "                T_var = T_var * marginals\n",
        "                # i.e., how a neuron of 2nd model is constituted by the neurons of 1st model\n",
        "                # this should all be ones, and number equal to number of neurons in 2nd model\n",
        "                print(T_var.sum(dim=0))\n",
        "                # assert (T_var.sum(dim=0) == torch.ones(T_var.shape[1], dtype=T_var.dtype).to(device)).all()\n",
        "\n",
        "        #if args.debug:\n",
        "        #    if idx == (num_layers - 1):\n",
        "        #        print(\"there goes the last transport map: \\n \", T_var)\n",
        "        #    else:\n",
        "        #        print(\"there goes the transport map at layer {}: \\n \".format(idx), T_var)\n",
        "        #    print(\"Ratio of trace to the matrix sum: \", torch.trace(T_var) / torch.sum(T_var))\n",
        "\n",
        "        #print(\"Ratio of trace to the matrix sum: \", torch.trace(T_var) / torch.sum(T_var))\n",
        "        #print(\"Here, trace is {} and matrix sum is {} \".format(torch.trace(T_var), torch.sum(T_var)))\n",
        "        #setattr(args, 'trace_sum_ratio_{}'.format(layer0_name), (torch.trace(T_var) / torch.sum(T_var)).item())\n",
        "\n",
        "        if past_correction:\n",
        "            print(\"this is past correction for weight mode\")\n",
        "            print(\"Shape of aligned wt is \", aligned_wt.shape)\n",
        "            print(\"Shape of fc_layer0_weight_data is \", fc_layer0_weight_data.shape)\n",
        "            t_fc0_model = torch.matmul(T_var.t(), aligned_wt.contiguous().view(aligned_wt.shape[0], -1))\n",
        "        else:\n",
        "            t_fc0_model = torch.matmul(T_var.t(), fc_layer0_weight_data.view(fc_layer0_weight_data.shape[0], -1))\n",
        "\n",
        "        # Average the weights of aligned first layers\n",
        "        if ensemble_step != 0.5:\n",
        "            geometric_fc = ((1-ensemble_step) * t_fc0_model +\n",
        "                            ensemble_step * fc_layer1_weight_data.view(fc_layer1_weight_data.shape[0], -1))\n",
        "        else:\n",
        "            geometric_fc = (t_fc0_model + fc_layer1_weight_data.view(fc_layer1_weight_data.shape[0], -1))/2\n",
        "        if is_conv and layer_shape != geometric_fc.shape:\n",
        "            geometric_fc = geometric_fc.view(layer_shape)\n",
        "            \n",
        "        avg_aligned_layers.append(geometric_fc)\n",
        "\n",
        "        # get the performance of the model 0 aligned with respect to the model 1\n",
        "        if eval_aligned:\n",
        "            raise Exception(\"Deleted code.\")\n",
        "\n",
        "    return avg_aligned_layers"
      ],
      "metadata": {
        "id": "ZyX-TwKDFfc4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test(args, network, test_loader, log_dict, debug=False, return_loss=False, is_local=False):\n",
        "    network.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    if is_local:\n",
        "        print(\"\\n--------- Testing in local mode ---------\")\n",
        "    else:\n",
        "        print(\"\\n--------- Testing in global mode ---------\")\n",
        "\n",
        "    for data, target in test_loader:\n",
        "        if GPU_USED!=-1:\n",
        "            data = data.cuda(GPU_USED)\n",
        "            target = target.cuda(GPU_USED)\n",
        "\n",
        "        output = network(data)\n",
        "        if debug:\n",
        "            print(\"output is \", output)\n",
        "\n",
        "        # mnist models return log_softmax outputs, while cifar ones return raw values!    \n",
        "        test_loss += F.nll_loss(output, target, size_average=False).item()\n",
        "\n",
        "        pred = output.data.max(1, keepdim=True)[1]\n",
        "        correct += pred.eq(target.data.view_as(pred)).sum()\n",
        "\n",
        "    print(\"size of test_loader dataset: \", len(test_loader.dataset))\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "    if is_local:\n",
        "        string_info = 'local_test'\n",
        "    else:\n",
        "        string_info = 'test'\n",
        "    log_dict['{}_losses'.format(string_info)].append(test_loss)\n",
        "    print('\\nTest set: Avg. loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "        test_loss, correct, len(test_loader.dataset),\n",
        "        100. * correct / len(test_loader.dataset)))\n",
        "\n",
        "    ans = (float(correct) * 100.0) / len(test_loader.dataset)\n",
        "\n",
        "    if not return_loss:\n",
        "        return ans\n",
        "    else:\n",
        "        return ans, test_loss"
      ],
      "metadata": {
        "id": "bp_NBFXCQyrn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_network_from_param_list(args, param_list, test_loader):\n",
        "\n",
        "    print(\"using independent method\")\n",
        "    new_network = MlpNet()\n",
        "    if GPU_USED != -1:\n",
        "        new_network = new_network.cuda(GPU_USED)\n",
        "\n",
        "    # check the test performance of the network before\n",
        "    log_dict = {}\n",
        "    log_dict['test_losses'] = []\n",
        "    test(args, new_network, test_loader, log_dict)\n",
        "\n",
        "    # set the weights of the new network\n",
        "    # print(\"before\", new_network.state_dict())\n",
        "    print(\"len of model parameters and avg aligned layers is \", len(list(new_network.parameters())),\n",
        "          len(param_list))\n",
        "    assert len(list(new_network.parameters())) == len(param_list)\n",
        "\n",
        "    layer_idx = 0\n",
        "    model_state_dict = new_network.state_dict()\n",
        "\n",
        "    print(\"len of model_state_dict is \", len(model_state_dict.items()))\n",
        "    print(\"len of param_list is \", len(param_list))\n",
        "\n",
        "    for key, value in model_state_dict.items():\n",
        "        model_state_dict[key] = param_list[layer_idx]\n",
        "        layer_idx += 1\n",
        "\n",
        "    new_network.load_state_dict(model_state_dict)\n",
        "\n",
        "    # check the test performance of the network after\n",
        "    log_dict = {}\n",
        "    log_dict['test_losses'] = []\n",
        "    acc = test(args, new_network, test_loader, log_dict)\n",
        "\n",
        "    return acc, new_network"
      ],
      "metadata": {
        "id": "p1d0fb2oQchq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Main"
      ],
      "metadata": {
        "id": "5LxplH0w2L1k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model A\n"
      ],
      "metadata": {
        "id": "eZkvgn8qUSrc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "args = None\n",
        "model_A, accuracy_A = get_pretrained_model(os.path.join('mnist_models', 'model_{}/{}.checkpoint'.format(0, \"final\")))\n",
        "print(\"Accuracy of the model A is {}\".format(accuracy_A))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cN_yiAb4w3o-",
        "outputId": "8f6567a7-ce6f-46a8-949d-795df483f33c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading model at path mnist_models/model_0/final.checkpoint which had accuracy 97.72 and at epoch 10\n",
            "Accuracy of the model A is 97.72\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model B"
      ],
      "metadata": {
        "id": "N-zjV-3AUUe4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_B, accuracy_B = get_pretrained_model(os.path.join('mnist_models', 'model_{}/{}.checkpoint'.format(1, \"final\")))\n",
        "print(\"Accuracy of the model B is {}\".format(accuracy_B))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zj6TQH7gw5H_",
        "outputId": "b2a2b7b5-301a-461b-e123-fc151038bf7a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading model at path mnist_models/model_1/final.checkpoint which had accuracy 97.75 and at epoch 10\n",
            "Accuracy of the model B is 97.75\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "models = [model_A, model_B]"
      ],
      "metadata": {
        "id": "TXFKTcYXzAnu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Merge using Wasserstein distance on weights"
      ],
      "metadata": {
        "id": "aX9ZmDC3UXWt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader, test_loader = get_dataloader()"
      ],
      "metadata": {
        "id": "SN2wo0v_1tSS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "activations = get_model_activations(args, models, config=None)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AsEkRD9P355c",
        "outputId": "7c787e08-f041-4566-c39c-29e68d56f35f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "excluded\n",
            "set forward hook for layer named:  fc1\n",
            "set forward hook for layer named:  fc2\n",
            "set forward hook for layer named:  fc3\n",
            "set forward hook for layer named:  fc4\n",
            "excluded\n",
            "set forward hook for layer named:  fc1\n",
            "set forward hook for layer named:  fc2\n",
            "set forward hook for layer named:  fc3\n",
            "set forward hook for layer named:  fc4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-7-01db55b01c47>:32: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return F.log_softmax(x)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "num_personal_idx  25\n",
            "***********\n",
            "min of act: -5.856302261352539, max: 6.365192413330078, mean: 0.17359121143817902\n",
            "***********\n",
            "min of act: -4.619015693664551, max: 6.780395030975342, mean: 0.6691511273384094\n",
            "***********\n",
            "min of act: -3.651808261871338, max: 8.595135688781738, mean: 1.1734567880630493\n",
            "***********\n",
            "min of act: -16.986865997314453, max: 20.3438777923584, mean: 0.12098681926727295\n",
            "***********\n",
            "min of act: -7.680006980895996, max: 7.137477874755859, mean: 0.16358400881290436\n",
            "***********\n",
            "min of act: -3.20451021194458, max: 5.538113594055176, mean: 0.6972481608390808\n",
            "***********\n",
            "min of act: -4.823601722717285, max: 10.422501564025879, mean: 1.0863652229309082\n",
            "***********\n",
            "min of act: -17.061927795410156, max: 21.255226135253906, mean: -0.3012940585613251\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def merge_models_wts(args, models, train_loader, test_loader, activations):\n",
        "    avg_aligned_layers = get_wassersteinized_layers_modularized(args, models, activations, test_loader=test_loader)\n",
        "    return get_network_from_param_list(args, avg_aligned_layers, test_loader)"
      ],
      "metadata": {
        "id": "uT1FOuRmFS8q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "geometric_acc, geometric_model = merge_models_wts(args, models, train_loader, test_loader, activations)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6KKnscyYCxoi",
        "outputId": "7112d9eb-d2ea-4e08-a694-5806c1930a3e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing the coordinates to form ground_metric\n",
            "dont leave off the squaring of the ground metric\n",
            "returns a uniform measure of cardinality:  400\n",
            "returns a uniform measure of cardinality:  400\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/ot/bregman.py:535: UserWarning: Sinkhorn did not converge. You might want to increase the number of iterations `numItermax` or the regularization parameter `reg`.\n",
            "  warnings.warn(\"Sinkhorn did not converge. You might want to \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "this is past correction for weight mode\n",
            "Shape of aligned wt is  torch.Size([400, 784])\n",
            "Shape of fc_layer0_weight_data is  torch.Size([400, 784])\n",
            "shape of layer: model 0 torch.Size([200, 400])\n",
            "shape of layer: model 1 torch.Size([200, 400])\n",
            "shape of previous transport map torch.Size([400, 400])\n",
            "Processing the coordinates to form ground_metric\n",
            "dont leave off the squaring of the ground metric\n",
            "returns a uniform measure of cardinality:  200\n",
            "returns a uniform measure of cardinality:  200\n",
            "this is past correction for weight mode\n",
            "Shape of aligned wt is  torch.Size([200, 400])\n",
            "Shape of fc_layer0_weight_data is  torch.Size([200, 400])\n",
            "shape of layer: model 0 torch.Size([100, 200])\n",
            "shape of layer: model 1 torch.Size([100, 200])\n",
            "shape of previous transport map torch.Size([200, 200])\n",
            "Processing the coordinates to form ground_metric\n",
            "dont leave off the squaring of the ground metric\n",
            "returns a uniform measure of cardinality:  100\n",
            "returns a uniform measure of cardinality:  100\n",
            "this is past correction for weight mode\n",
            "Shape of aligned wt is  torch.Size([100, 200])\n",
            "Shape of fc_layer0_weight_data is  torch.Size([100, 200])\n",
            "shape of layer: model 0 torch.Size([10, 100])\n",
            "shape of layer: model 1 torch.Size([10, 100])\n",
            "shape of previous transport map torch.Size([100, 100])\n",
            "Processing the coordinates to form ground_metric\n",
            "dont leave off the squaring of the ground metric\n",
            "returns a uniform measure of cardinality:  10\n",
            "returns a uniform measure of cardinality:  10\n",
            "this is past correction for weight mode\n",
            "Shape of aligned wt is  torch.Size([10, 100])\n",
            "Shape of fc_layer0_weight_data is  torch.Size([10, 100])\n",
            "using independent method\n",
            "\n",
            "--------- Testing in global mode ---------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/ot/bregman.py:502: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  v = b / KtransposeU\n",
            "/usr/local/lib/python3.9/dist-packages/ot/bregman.py:510: UserWarning: Warning: numerical errors at iteration 0\n",
            "  warnings.warn('Warning: numerical errors at iteration %d' % ii)\n",
            "<ipython-input-7-01db55b01c47>:32: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return F.log_softmax(x)\n",
            "/usr/local/lib/python3.9/dist-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "size of test_loader dataset:  10000\n",
            "\n",
            "Test set: Avg. loss: 2.3056, Accuracy: 686/10000 (7%)\n",
            "\n",
            "len of model parameters and avg aligned layers is  4 4\n",
            "len of model_state_dict is  4\n",
            "len of param_list is  4\n",
            "\n",
            "--------- Testing in global mode ---------\n",
            "size of test_loader dataset:  10000\n",
            "\n",
            "Test set: Avg. loss: 0.6911, Accuracy: 9497/10000 (95%)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Vanilla Ensembling\n"
      ],
      "metadata": {
        "id": "To4dO5RyS127"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_avg_parameters(networks, weights=None):\n",
        "    avg_pars = []\n",
        "    for par_group in zip(*[net.parameters() for net in networks]):\n",
        "        if weights is not None:\n",
        "            weighted_par_group = [par * weights[i] for i, par in enumerate(par_group)]\n",
        "            avg_par = torch.sum(torch.stack(weighted_par_group), dim=0)\n",
        "        else:\n",
        "            avg_par = torch.mean(torch.stack(par_group), dim=0)\n",
        "        avg_pars.append(avg_par)\n",
        "    return avg_pars"
      ],
      "metadata": {
        "id": "mr2WDUc7S7N4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def naive_ensembling(args, networks, test_loader):\n",
        "    # simply average the weights in networks\n",
        "    \n",
        "    if width_ratio != 1:\n",
        "        print(\"Unfortunately naive ensembling can't work if models are not of same shape!\")\n",
        "        return -1, None\n",
        "    weights = [(1-ensemble_step), ensemble_step]\n",
        "    avg_pars = get_avg_parameters(networks, weights)\n",
        "    ensemble_network = MlpNet()\n",
        "    # put on GPU\n",
        "    if GPU_USED!=-1:\n",
        "        ensemble_network = ensemble_network.cuda(GPU_USED)\n",
        "\n",
        "    # check the test performance of the method before\n",
        "    log_dict = {}\n",
        "    log_dict['test_losses'] = []\n",
        "    test(args, ensemble_network, test_loader, log_dict)\n",
        "\n",
        "    # set the weights of the ensembled network\n",
        "    for idx, (name, param) in enumerate(ensemble_network.state_dict().items()):\n",
        "        ensemble_network.state_dict()[name].copy_(avg_pars[idx].data)\n",
        "\n",
        "    # check the test performance of the method after ensembling\n",
        "    log_dict = {}\n",
        "    log_dict['test_losses'] = []\n",
        "    \n",
        "    return test(args, ensemble_network, test_loader, log_dict), ensemble_network"
      ],
      "metadata": {
        "id": "VrSa7ZMjS3wu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vanilla_acc, vanilla_ensemble_model = naive_ensembling(args, models, test_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Cb9smxiS-x3",
        "outputId": "4b850bce-3616-4077-ed6c-8ff25469db4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--------- Testing in global mode ---------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-7-01db55b01c47>:32: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return F.log_softmax(x)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "size of test_loader dataset:  10000\n",
            "\n",
            "Test set: Avg. loss: 2.3044, Accuracy: 810/10000 (8%)\n",
            "\n",
            "\n",
            "--------- Testing in global mode ---------\n",
            "size of test_loader dataset:  10000\n",
            "\n",
            "Test set: Avg. loss: 1.2654, Accuracy: 7384/10000 (74%)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Results"
      ],
      "metadata": {
        "id": "TE5LDQJtVKwy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_A"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iTzsBzW_VPIb",
        "outputId": "b4fe1c02-e47f-4141-da02-02bb8920fceb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "97.72"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_B"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jqOcTHGdVWup",
        "outputId": "24ef4c6a-daa7-4126-f646-65dd6b815050"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "97.75"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "geometric_acc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1xwYAdeqVOmV",
        "outputId": "b1d72039-b65d-48a6-d8ec-3c026d1cc932"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "94.97"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vanilla_acc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SUBYMAbYVQKi",
        "outputId": "3edfec80-8500-41ee-90f4-f33118508cf9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "73.84"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    }
  ]
}